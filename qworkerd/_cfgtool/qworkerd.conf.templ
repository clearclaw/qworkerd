#! /usr/bin/env python

from path import Path

LOG = logging.getLogger (__name__)

# Where is RabbitMQ?
BROKER_URL = "${qworkerd_broker_url}"

# The backend used to store task results (tombstones). 
# CELERY_RESULT_BACKEND = "db+mysql://root:root@localhost/qeventlog"
# CELERY_RESULT_BACKEND = "cache+memcached://127.0.0.1:11211/"
CELERY_RESULT_BACKEND = "${qworkerd_result_backend}"

# Not clear this is needed in the queue case?
SECRET_KEY = "${qworkerd_secret_key}"

# Entry for logging exceptions to Sentry
RAVEN_CONFIG = {
  "dsn": "sync+${qworkerd_sentry_dsn}",
}

# Number of simultaneous jobs to run on the worker
CELERYD_CONCURRENCY = ${qworkerd_job_parallel}

# Task hard time limit in seconds. The worker processing the task will
# be killed and replaced with a new one when this is exceeded.
CELERYD_TASK_TIME_LIMIT = ${qworkerd_job_time_killafter}

# Task soft time limit in seconds.
# The SoftTimeLimitExceeded exception will be raised when this is
# exceeded. The task can catch this to e.g. clean up before the hard
# time limit comes.
# http://celery.readthedocs.org/en/latest/configuration.html#celeryd-task-soft-time-limit
CELERYD_TASK_SOFT_TIME_LIMIT = ${qworkerd_job_time_warning}

# A sequence of modules to import when the worker starts.
CELERY_INCLUDE = "${qworkerd_job_include}".split (",")
